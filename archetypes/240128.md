---
title: "Weekly Summary 6"
types: "weeklysummary"
date: 2024-01-21T12:30:00+08:00
location: "科大高新区"
img_url: 
onlineLink: 
abstract: ""
KeyWords:
---



## 本周的工作

1. Mon: 
2. Tues：

3. Wed：

4. Thurs： 

5. Fri: 

6. Sat: 

7. Sun：

| metrics               | Monday | Tuesday | Wednesday | Thursday | Friday | Saturday | Sunday |
|-----------------------|--------|---------|-----------|----------|--------|----------|--------|
| Get up                | 8:55   |         |           |          |        |          |        |
| Running               |        |         |           |          |        |          |        |
| In-door Exercise(2~3) |        |         |           |          |        |          |        |
| Release               |        |         |           |          |        |          |        |
| Fall Sleep            |        |         |           |          |        |          |        |
| Night Think           |        |         |           |          |        |          |        |
| Resleep               |        |         |           |          |        |          |        |

1. 室内运动: 建议每半天一次(早起和晚归)。内容仰卧起坐(包括侧卧)，平板支撑，俯卧撑，Kegel
2. 睡觉时间以平板时间为准。

{{< mdImg >}}

{{% admonition note "深夜思考的坏处" %}}

1. 打乱作息。
2. 思考完后大脑活跃，但是身体已经扛不住了。
3. 需要看relax视频，转移大脑注意力

{{% /admonition %}}

## 下周任务优先级



## AI 相关的拓展阅读

<!-- []() -->

https://github.com/chenzomi12/DeepLearningSystem/blob/main/02Hardware/02ChipBase/05.gpu.pdf

### 硬件设计

[软硬协同优化 (4)：指令集设计概述](https://mp.weixin.qq.com/s/aTsfKlih9pv-l-Q-iqKLcw)

### AI模型

[现在LLM 的大小为什么都设计成6/7B、13B和130B几个档次？解析大模型中的Scaling Law](https://mp.weixin.qq.com/s/-JwiRvYAo61RG6iHHhwmVg)

### 瓶颈与性能分析（成本）

[Memory Wall in Neural Network Inference](https://blog.csdn.net/qq_49588762/article/details/135528513)

[CPU推理](https://mp.weixin.qq.com/s/vb1U_tQ79rsNjUwuTUoD9Q)

mike:
https://le.qun.ch/en/blog/2023/05/13/transformer-batching/

mike:
Dissecting Batching Effects in GPT Inference 一个blog你们可能会感兴趣，有GPT inference的内存墙分析

mike:
https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices


### 国内产品的硬件差距 

1. [国产GPU新势力摩尔线程](https://mp.weixin.qq.com/s/u-hwp7kBTW7fOgDlNNKkRQ)
2. [国产GPU，可堪大用吗？系列之二：神秘的910B](https://mp.weixin.qq.com/s/olWs3I5kHSNPQhSe-SjKcw)
2. [英伟达 vs. 华为海思：GPU性能一览](https://mp.weixin.qq.com/s/d8rdGy8NNbxyqNVU8y11WQ)
昇腾910B 达芬奇 gpuScratchpad
思元690
深水4号


### 国外先进制程

[拆掉英伟达护城河，细节曝光！世界最快超算用3072块AMD GPU训完超万亿参数LLM](https://mp.weixin.qq.com/s/QPAxuBmrr1O6H0LjwiMMxA)


### 任务评估与时间分配


|         | 紧急性(3) | 重要性(3) | 喜好(1) | 工作量(3) | 总分 | 分配   | 要求 |
|---------|-----------|-----------|---------|-----------|------|--------|------|
| thesis  | 3         | 3         | 0       | 3         | 9    | 四天多 | 3    |
| AI      | 1         | 2         | 1       | 2         | 6    | 两天欠 | 1    |
| web     | 1         | 0         | 0       | 1         | 2    | 一天欠 | 1    |
| Summary |           |           |         |           | 21   |        |      |


{{% admonition note "提倡多进程工作" %}}

1. 虽然可能会陷入上下午切换导致的效率损失。
2. 但是不同于CPU，人脑可以在多进程之间提取通用的思想，融会贯通。
3. 另一个好处是，任务开展后才能知道其中的难点，和大约耗时，才有助于实时调整策略应对。不会导致措手不及的狼狈下场。

{{% /admonition %}}


{{% admonition note "HUAWEI 计算产品线" %}}

### 工作内容

1. 算子底层npu异常检测，内存踩踏，越界。
2. 高层模型层级，提高精度，算法强相关。
3. (传统内容的创新)基于性能建模，推理和训练加速。

{{% /admonition %}}

{{% admonition note "Baidu ai for system" %}}

### 团队

- 百度编译器 晓光
- 10几个人，后端上海，前端北京。
- **尖酸小黄鸭：T9 - 半年**
- **T5 -清华的硕士**：AI编译器前端，OP → 机器码→kernel。循环融合。

### 工作内容

- 鲁棒性(容忍输入扰动的稳定性，处理出错情况的可靠性)，正确性，AI原生的思维。
- 后端 code阵列，

#### AI 编译器

- 中间理论：代数结构，形式化下来。多个**op循环融合**，map ADT（Abstract Data Type"，即抽象数据类型？）
- TVM autotune op规则
- torch 负优化 - 形式化定义，算子以及约束。 A B op融合

{{% /admonition %}}


{{% admonition note "中文版的周报" %}}

{{% /admonition %}}

{{% admonition note "Pls correct the grammar and turn this to a weekly report email(not the first time) to Qingcai in easy-understanding english:" %}}


{{% /admonition %}}